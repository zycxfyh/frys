# Frys Workflow Engine (frys-workflow-engine)

## ğŸ¯ æ ¸å¿ƒä½¿å‘½ï¼šAI Agentåä½œç¤¾ä¼šçš„æ“ä½œç³»ç»Ÿ

**Frys Workflow Engine æ˜¯æ•´ä¸ªç³»ç»Ÿçš„ç¥ç»ä¸­æ¢å’Œå¿ƒè„**ï¼Œå®ƒæ˜¯**å¼ é‡åŸç”Ÿã€è‡ªç»„ç»‡ã€è‡ªä¸»è¿›åŒ–**çš„å·¥ä½œæµæ‰§è¡Œå¹³å°ã€‚

**ä¸å†æ˜¯ä¼ ç»Ÿçš„"æµç¨‹è‡ªåŠ¨åŒ–å·¥å…·"ï¼Œè€Œæ˜¯AI Agentåä½œç¤¾ä¼šçš„æ“ä½œç³»ç»Ÿ**ï¼Œè®©æ™ºèƒ½ä½“ä»¬èƒ½å¤Ÿè‡ªä¸»åä½œã€å…±åŒè¿›åŒ–ã€åˆ›é€ ä»·å€¼ã€‚

### ğŸŒŸ æ ¸å¿ƒå®šä½
- **ğŸ­ Frysçš„çµé­‚**ï¼šæ‰€æœ‰å…¶ä»–æ¨¡å—éƒ½æ˜¯ä¸ºäº†æœåŠ¡å’Œå¢å¼ºå·¥ä½œæµç³»ç»Ÿ
- **ğŸ¤– AI Agentçš„å®¶å›­**ï¼šä¸ºå¤šAgentåä½œæä¾›åŸºç¡€è®¾æ–½
- **ğŸ§¬ è¿›åŒ–å¼•æ“**ï¼šé€šè¿‡è¯•é”™å­¦ä¹ æŒç»­ä¼˜åŒ–å·¥ä½œæµæ‰§è¡Œ

## ğŸ§¬ ä¸–ç•Œæ¨¡å‹æ¶æ„ï¼šå¼ é‡åŸç”Ÿå·¥ä½œæµç³»ç»Ÿ

åŸºäºFrysä¸–ç•Œæ¨¡å‹æ¡†æ¶ï¼Œå·¥ä½œæµå¼•æ“é‡‡ç”¨äº†é©å‘½æ€§çš„è®¾è®¡ç†å¿µï¼š

### 1. **å¼ é‡åŸç”Ÿè¡¨ç¤º** - æ•°æ®è¡¨ç¤ºçš„æ•°å­¦é©å‘½
```rust
// ä¼ ç»Ÿï¼šXML/JSONæ–‡æœ¬å®šä¹‰
{
  "nodes": [...],
  "edges": [...]
}

// Frysï¼šæ•°å­¦å¼ é‡è¡¨ç¤º
pub struct WorkflowTensor {
    pub node_tensor: Tensor,      // èŠ‚ç‚¹å±æ€§ [num_nodes, features]
    pub edge_tensor: Tensor,      // ä¾èµ–å…³ç³» [num_nodes, num_nodes, features]
    pub execution_tensor: Tensor, // æ‰§è¡ŒçŠ¶æ€ [time_steps, num_nodes, states]
    pub optimization_tensor: Tensor, // ä¼˜åŒ–ç­–ç•¥ [optimization_dims]
}
```

**å¼ é‡ä¼˜åŠ¿**ï¼š
- **å¹¶è¡Œè®¡ç®—**ï¼šä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ªå·¥ä½œæµå›¾ï¼Œ10x+ æ€§èƒ½æå‡
- **æ™ºèƒ½ä¼˜åŒ–**ï¼šç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•è‡ªåŠ¨ä¼˜åŒ–æ‰§è¡Œè·¯å¾„
- **æ¨¡å¼å­¦ä¹ **ï¼šè‡ªåŠ¨å‘ç°å’Œå­¦ä¹ æ‰§è¡Œæ¨¡å¼

### 2. **è‡ªç»„ç»‡Agentåä½œ** - ä»å·¥å…·åˆ°ç¤¾ä¼šçš„è¿›åŒ–
```rust
// ä¼ ç»Ÿï¼šè¢«åŠ¨æ‰§è¡Œå™¨
pub struct TraditionalNode {
    pub execute: fn(input) -> output, // å›ºå®šé€»è¾‘
}

// Frysï¼šè‡ªä¸»Agent
pub struct WorkflowAgent {
    pub capability_tensor: Tensor,    // èƒ½åŠ›è¯„ä¼°
    pub collaboration_interface: Arc<CollaborationInterface>, // åä½œé€šä¿¡
    pub learning_tensor: Tensor,      // è¿›åŒ–çŸ¥è¯†
}
```

**Agentç‰¹æ€§**ï¼š
- **è‡ªä¸»å†³ç­–**ï¼šæ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æœ€ä¼˜æ‰§è¡Œç­–ç•¥
- **åä½œåå•†**ï¼šä¸å…¶ä»–Agentåå•†ä»»åŠ¡åˆ†é…
- **æŒç»­å­¦ä¹ **ï¼šä»æ‰§è¡Œç»“æœä¸­æ”¹è¿›è‡ªå·±

### 3. **å®ç”¨å­¦ä¹ ä¼˜åŒ–** - åŸºäºå†å²çš„æŒç»­æ”¹è¿›

å¸æ”¶**æ··åˆè®°å¿†ç³»ç»Ÿ**å’Œ**è‡ªä¸»å­¦ä¹ **æ€æƒ³ï¼Œæä¾›åŠ¡å®çš„å­¦ä¹ ä¼˜åŒ–åŠŸèƒ½ï¼š

```rust
// å·¥ä½œæµå­¦ä¹ ä¼˜åŒ–å™¨ - åŸºäºæ‰§è¡Œå†å²çš„å®ç”¨ä¼˜åŒ–
pub struct WorkflowLearningOptimizer {
    pub execution_analyzer: ExecutionAnalyzer,
    pub suggestion_generator: SuggestionGenerator,
    pub user_approval_system: UserApprovalSystem, // äººå·¥å®¡æ ¸æœºåˆ¶
}

impl WorkflowLearningOptimizer {
    // ä»æ‰§è¡Œå†å²ä¸­å­¦ä¹ å¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®
    pub async fn learn_and_suggest(&self, workflow_id: &str) -> Result<Vec<OptimizationSuggestion>, LearningError> {
        // 1. åˆ†ææ‰§è¡Œå†å²æ¨¡å¼
        let history = self.load_execution_history(workflow_id)?;
        let patterns = self.execution_analyzer.analyze_patterns(&history)?;

        // 2. ç”Ÿæˆå…·ä½“çš„ä¼˜åŒ–å»ºè®®
        let suggestions = self.suggestion_generator.generate_suggestions(&patterns)?;

        // 3. è¿‡æ»¤æ‰é£é™©è¾ƒé«˜çš„å»ºè®®
        let safe_suggestions = self.filter_risky_suggestions(suggestions)?;

        Ok(safe_suggestions)
    }

    // åº”ç”¨ä¼˜åŒ–å»ºè®®ï¼ˆéœ€è¦äººå·¥ç¡®è®¤ï¼‰
    pub async fn apply_optimization_with_approval(&self, suggestion: &OptimizationSuggestion, user_approval: &UserApproval) -> Result<(), LearningError> {
        // 1. éªŒè¯ç”¨æˆ·æ‰¹å‡†
        self.user_approval_system.verify_approval(user_approval, suggestion)?;

        // 2. åˆ›å»ºå¤‡ä»½ï¼ˆä»¥é˜²ä¸‡ä¸€ï¼‰
        self.create_backup_before_optimization(suggestion)?;

        // 3. åº”ç”¨ä¼˜åŒ–
        self.apply_optimization(suggestion)?;

        // 4. ç›‘æ§æ•ˆæœ
        self.monitor_optimization_effect(suggestion).await?;

        Ok(())
    }
}
```

**å®ç”¨ä¼˜åŒ–æœºåˆ¶**ï¼š
- **å†å²åˆ†æ**ï¼šåŸºäºå®é™…æ‰§è¡Œæ•°æ®è¯†åˆ«æ”¹è¿›æœºä¼š
- **äººå·¥å®¡æ ¸**ï¼šæ‰€æœ‰ä¼˜åŒ–å»ºè®®éƒ½éœ€è¦äººå·¥ç¡®è®¤
- **æ¸è¿›æ”¹è¿›**ï¼šä»å°è§„æ¨¡ä¼˜åŒ–å¼€å§‹ï¼Œç¡®ä¿ç¨³å®šæ€§
- **æ•ˆæœç›‘æ§**ï¼šæŒç»­ç›‘æ§ä¼˜åŒ–æ•ˆæœï¼Œå¿…è¦æ—¶å›æ»š

### 4. **å¤šæ¨¡æ€æ•°æ®æ”¯æŒ** - æ‰©å±•å·¥ä½œæµè¾“å…¥èƒ½åŠ›

å¸æ”¶**å¤šæ¨¡æ€ç‰¹å¾æå–ä¸èåˆ**æŠ€æœ¯ï¼Œæ”¯æŒå·¥ä½œæµå¤„ç†å¤šç§æ•°æ®ç±»å‹ï¼š

```rust
// å¤šæ¨¡æ€æ•°æ®å¤„ç†èŠ‚ç‚¹ - å¤„ç†å›¾åƒã€éŸ³é¢‘ã€æ–‡æœ¬ç­‰å¤šæ¨¡æ€è¾“å…¥
pub struct MultimodalDataNode {
    pub vision_processor: Option<VisionProcessor>,    // å›¾åƒå¤„ç†
    pub audio_processor: Option<AudioProcessor>,      // éŸ³é¢‘å¤„ç†
    pub text_processor: Option<TextProcessor>,        // æ–‡æœ¬å¤„ç†
    pub fusion_strategy: ModalityFusionStrategy,      // èåˆç­–ç•¥
}

impl MultimodalDataNode {
    pub async fn process_multimodal_input(&self, input: &WorkflowInput) -> Result<ProcessedData, ProcessingError> {
        let mut processed_modalities = Vec::new();

        // å¹¶è¡Œå¤„ç†ä¸åŒæ¨¡æ€æ•°æ®
        if let Some(vision) = &self.vision_processor {
            if let Some(image_data) = input.extract_image_data()? {
                let vision_features = vision.extract_features(&image_data).await?;
                processed_modalities.push(ModalityData::Vision(vision_features));
            }
        }

        if let Some(audio) = &self.audio_processor {
            if let Some(audio_data) = input.extract_audio_data()? {
                let audio_features = audio.extract_features(&audio_data).await?;
                processed_modalities.push(ModalityData::Audio(audio_features));
            }
        }

        if let Some(text) = &self.text_processor {
            if let Some(text_data) = input.extract_text_data()? {
                let text_features = text.extract_features(&text_data).await?;
                processed_modalities.push(ModalityData::Text(text_features));
            }
        }

        // æ ¹æ®ç­–ç•¥èåˆå¤šæ¨¡æ€æ•°æ®
        let fused_data = match self.fusion_strategy {
            ModalityFusionStrategy::SimpleConcat => self.concatenate_modalities(&processed_modalities)?,
            ModalityFusionStrategy::AttentionFusion => self.attention_based_fusion(&processed_modalities).await?,
            ModalityFusionStrategy::CrossModalAlign => self.cross_modal_alignment(&processed_modalities).await?,
        };

        Ok(fused_data)
    }
}
```

**å®é™…åº”ç”¨åœºæ™¯**ï¼š
- **æ™ºèƒ½æ–‡æ¡£å¤„ç†**ï¼šå¤„ç†åŒ…å«å›¾ç‰‡ã€è¡¨æ ¼ã€æ‰‹å†™æ–‡å­—çš„å¤æ‚æ–‡æ¡£
- **å¤šåª’ä½“å†…å®¹åˆ†æ**ï¼šåˆ†æç”¨æˆ·ä¸Šä¼ çš„è§†é¢‘ã€éŸ³é¢‘ç­‰å¤šåª’ä½“å†…å®¹
- **è·¨æ¨¡æ€å†³ç­–æ”¯æŒ**ï¼šåŸºäºå¤šç§è¾“å…¥æ¨¡æ€åšå‡ºæ›´å‡†ç¡®çš„ä¸šåŠ¡å†³ç­–

### 5. **å¢å¼ºé€šä¿¡åè®®** - å¸æ”¶åŸç”Ÿå¼ é‡åè®®

å¸æ”¶**åŸç”Ÿå¼ é‡åè®®**æŠ€æœ¯ï¼Œæå‡å·¥ä½œæµç»„ä»¶é—´çš„é€šä¿¡æ•ˆç‡ï¼š

```rust
// å¼ é‡ä¼˜åŒ–çš„å·¥ä½œæµé€šä¿¡åè®®
pub struct TensorOptimizedWorkflowProtocol {
    pub tensor_serializer: TensorSerializer,
    pub compression_engine: CompressionEngine,
    pub zero_copy_transport: ZeroCopyTransport,
}

impl TensorOptimizedWorkflowProtocol {
    // é«˜æ•ˆä¼ è¾“å·¥ä½œæµçŠ¶æ€å’Œæ•°æ®
    pub async fn transmit_workflow_state(&self, state: &WorkflowExecutionState) -> Result<(), TransmissionError> {
        // 1. å°†å·¥ä½œæµçŠ¶æ€è½¬æ¢ä¸ºå¼ é‡è¡¨ç¤º
        let state_tensor = self.convert_state_to_tensor(state)?;

        // 2. åº”ç”¨æ™ºèƒ½å‹ç¼©
        let compressed_tensor = self.compression_engine.compress(&state_tensor)?;

        // 3. é›¶æ‹·è´ä¼ è¾“
        self.zero_copy_transport.transmit(&compressed_tensor)?;

        Ok(())
    }

    // æ¥æ”¶å’Œè§£ç å·¥ä½œæµæ•°æ®
    pub async fn receive_workflow_data(&self) -> Result<WorkflowData, TransmissionError> {
        // 1. é›¶æ‹·è´æ¥æ”¶
        let compressed_data = self.zero_copy_transport.receive()?;

        // 2. è§£å‹ç¼©
        let tensor_data = self.compression_engine.decompress(&compressed_data)?;

        // 3. è½¬æ¢ä¸ºå·¥ä½œæµæ•°æ®ç»“æ„
        let workflow_data = self.convert_tensor_to_workflow_data(&tensor_data)?;

        Ok(workflow_data)
    }
}
```

**æ€§èƒ½æå‡**ï¼š
- **ä¼ è¾“æ•ˆç‡**ï¼šå¼ é‡åºåˆ—åŒ–æ¯”JSONå¿«5-10x
- **å†…å­˜æ•ˆç‡**ï¼šæ™ºèƒ½å‹ç¼©å‡å°‘50%+å†…å­˜å ç”¨
- **CPUæ•ˆç‡**ï¼šé›¶æ‹·è´ä¼ è¾“å‡å°‘æ•°æ®æ‹·è´å¼€é”€

### 6. **è‡ªé€‚åº”èµ„æºè°ƒåº¦** - å¸æ”¶æœåŠ¡å‘ç°æŠ€æœ¯

å¸æ”¶**è‡ªç»„ç»‡æœåŠ¡å‘ç°**æ€æƒ³ï¼Œå®ç°å·¥ä½œæµèŠ‚ç‚¹çš„æ™ºèƒ½è°ƒåº¦ï¼š

```rust
// è‡ªé€‚åº”å·¥ä½œæµèŠ‚ç‚¹è°ƒåº¦å™¨
pub struct AdaptiveWorkflowScheduler {
    pub node_capability_registry: NodeCapabilityRegistry,
    pub load_predictor: LoadPredictor,
    pub performance_monitor: PerformanceMonitor,
}

impl AdaptiveWorkflowScheduler {
    // æ™ºèƒ½é€‰æ‹©æ‰§è¡ŒèŠ‚ç‚¹
    pub async fn select_optimal_node(&self, task: &Task, context: &ExecutionContext) -> Result<NodeAssignment, SchedulerError> {
        // 1. åŸºäºä»»åŠ¡éœ€æ±‚ç­›é€‰å€™é€‰èŠ‚ç‚¹
        let candidates = self.node_capability_registry.find_capable_nodes(task)?;

        // 2. è¯„ä¼°èŠ‚ç‚¹å½“å‰è´Ÿè½½å’Œæ€§èƒ½å†å²
        let node_assessments = self.assess_node_performance(&candidates).await?;

        // 3. é¢„æµ‹æ‰§è¡Œæ—¶é—´å’Œèµ„æºéœ€æ±‚
        let predictions = self.load_predictor.predict_execution_requirements(task, &node_assessments)?;

        // 4. é€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹ç»„åˆ
        let optimal_assignment = self.select_best_assignment(&candidates, &predictions)?;

        Ok(NodeAssignment {
            node_id: optimal_assignment.node_id,
            estimated_duration: optimal_assignment.duration,
            resource_allocation: optimal_assignment.resources,
            confidence_score: optimal_assignment.confidence,
        })
    }

    // åŠ¨æ€è°ƒæ•´èµ„æºåˆ†é…
    pub async fn adjust_resource_allocation(&self, execution_id: &str, current_metrics: &ExecutionMetrics) -> Result<(), SchedulerError> {
        // ç›‘æ§æ‰§è¡ŒæŒ‡æ ‡
        let performance_status = self.performance_monitor.analyze_metrics(current_metrics)?;

        // å¦‚æœå‘ç°æ€§èƒ½é—®é¢˜ï¼ŒåŠ¨æ€è°ƒæ•´
        if performance_status.needs_adjustment {
            let adjustment = self.calculate_resource_adjustment(&performance_status)?;
            self.apply_resource_adjustment(execution_id, &adjustment).await?;
        }

        Ok(())
    }
}
```

**å®é™…æ”¶ç›Š**ï¼š
- **æ™ºèƒ½è´Ÿè½½å‡è¡¡**ï¼šæ ¹æ®èŠ‚ç‚¹èƒ½åŠ›å’Œå½“å‰è´Ÿè½½æ™ºèƒ½åˆ†é…ä»»åŠ¡
- **æ€§èƒ½é¢„æµ‹**ï¼šæå‰é¢„æµ‹æ‰§è¡Œæ—¶é—´å’Œèµ„æºéœ€æ±‚
- **åŠ¨æ€ä¼˜åŒ–**ï¼šè¿è¡Œæ—¶æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´èµ„æºåˆ†é…
- **æ•…éšœè‡ªæ„ˆ**ï¼šè‡ªåŠ¨æ£€æµ‹å’Œå¤„ç†èŠ‚ç‚¹æ•…éšœ

## ğŸ¯ AOSæŠ€æœ¯æ ˆåœ¨å·¥ä½œæµä¸­çš„å®ç”¨ä»·å€¼

### æŠ€æœ¯å¸æ”¶ vs æ ¸å¿ƒä¿æŒ

æˆ‘ä»¬åšå®šåœ°ä»¥**å·¥ä½œæµç³»ç»Ÿ**ä¸ºæ ¸å¿ƒï¼Œä½†ä»AOSæŠ€æœ¯æ ˆä¸­å¸æ”¶å‰æ²¿èƒ½åŠ›æ¥å¢å¼ºå…¶å®ç”¨æ€§ï¼š

| AOSå‰æ²¿æŠ€æœ¯ | å·¥ä½œæµåº”ç”¨ | å®é™…æ”¶ç›Š |
|-------------|-----------|---------|
| **å¼ é‡åŸç”Ÿåè®®** | é«˜æ•ˆçŠ¶æ€ä¼ è¾“ | 5-10xé€šä¿¡æ€§èƒ½æå‡ |
| **æ··åˆè®°å¿†ç³»ç»Ÿ** | æ‰§è¡Œå†å²å­˜å‚¨ | æ™ºèƒ½åŒ–æ¨¡å¼è¯†åˆ« |
| **ç»“æ„åŒ–æ¨ç†** | å¢å¼ºå†³ç­–èŠ‚ç‚¹ | å¤æ‚ä¸šåŠ¡é€»è¾‘å¤„ç† |
| **å¤šæ¨¡æ€èåˆ** | å¤šåª’ä½“æ•°æ®å¤„ç† | æ‰©å±•è¾“å…¥èƒ½åŠ› |
| **è‡ªä¸»å­¦ä¹ ** | æ€§èƒ½ä¼˜åŒ–å»ºè®® | æŒç»­æ”¹è¿›ç³»ç»Ÿ |
| **è‡ªç»„ç»‡å‘ç°** | æ™ºèƒ½èŠ‚ç‚¹è°ƒåº¦ | èµ„æºåˆ©ç”¨ç‡æå‡ |

### æ ¸å¿ƒåŸåˆ™ï¼šå®ç”¨æ€§ä¼˜å…ˆ

- **ä¸æ”¹å˜å·¥ä½œæµæœ¬è´¨**ï¼šå§‹ç»ˆä¿æŒå¯é çš„ä¸šåŠ¡æµç¨‹ç®¡ç†èƒ½åŠ›
- **äººå·¥æ§åˆ¶ä¼˜åŒ–**ï¼šæ‰€æœ‰AIå¢å¼ºåŠŸèƒ½éƒ½éœ€è¦äººå·¥å®¡æ ¸ç¡®è®¤
- **æ¸è¿›å¼æ”¹è¿›**ï¼šä»å°è§„æ¨¡ä¼˜åŒ–å¼€å§‹ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§
- **å¯è§‚æµ‹æ€§ä¿éšœ**ï¼šæ‰€æœ‰å¢å¼ºåŠŸèƒ½éƒ½æœ‰å®Œæ•´çš„ç›‘æ§å’Œå›æ»šæœºåˆ¶

### å®é™…ä¸šåŠ¡ä»·å€¼

è¿™äº›AOSæŠ€æœ¯çš„å¸æ”¶ä¸ºå·¥ä½œæµç³»ç»Ÿå¸¦æ¥äº†å®å®åœ¨åœ¨çš„ä¸šåŠ¡ä»·å€¼ï¼š

1. **æ€§èƒ½æå‡20-50%**ï¼šé€šè¿‡æ™ºèƒ½ä¼˜åŒ–å’Œé«˜æ•ˆé€šä¿¡
2. **åŠŸèƒ½æ‰©å±•2x**ï¼šæ”¯æŒå¤šæ¨¡æ€è¾“å…¥å’Œå¤æ‚å†³ç­–é€»è¾‘
3. **è¿ç»´æ•ˆç‡æå‡**ï¼šè‡ªåŠ¨åŒ–æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–å»ºè®®
4. **ç”¨æˆ·ä½“éªŒæ”¹å–„**ï¼šæ›´æ™ºèƒ½çš„æ‰§è¡Œé¢„æµ‹å’Œèµ„æºåˆ†é…

### æ ¸å¿ƒç‰¹æ€§
- **ğŸ¤– AIåŸç”Ÿ**: å†…ç½®AIæ¨ç†å’Œå†³ç­–èƒ½åŠ›
- **âš¡ é«˜å¹¶å‘**: æ”¯æŒæ•°ä¸‡ä¸ªå¹¶å‘å·¥ä½œæµå®ä¾‹
- **ğŸ¨ å¯è§†åŒ–**: æ‹–æ‹½å¼å·¥ä½œæµè®¾è®¡å™¨
- **ğŸ“Š å®æ—¶ç›‘æ§**: å®Œæ•´çš„æ‰§è¡ŒçŠ¶æ€è¿½è¸ª
- **ğŸ”„ åŠ¨æ€è°ƒæ•´**: è¿è¡Œæ—¶å·¥ä½œæµä¿®æ”¹
- **ğŸ›¡ï¸ å®¹é”™æ€§**: è‡ªåŠ¨æ•…éšœæ¢å¤å’Œè¡¥å¿æœºåˆ¶

### æ¶æ„ä¼˜åŠ¿
- **æ€§èƒ½æè‡´**: Rustå®ç°çš„åŸç”Ÿæ€§èƒ½
- **æ‰©å±•æ— é™**: æ’ä»¶åŒ–èŠ‚ç‚¹å’Œè¿æ¥å™¨
- **æ™ºèƒ½å†³ç­–**: AIé©±åŠ¨çš„è·¯å¾„é€‰æ‹©å’Œä¼˜åŒ–
- **ç›‘æ§å…¨é¢**: ç«¯åˆ°ç«¯çš„å¯è§‚æµ‹æ€§
- **å¼€å‘å‹å¥½**: å£°æ˜å¼APIå’Œå¯è§†åŒ–å·¥å…·

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
frys-workflow-engine/
â”œâ”€â”€ Core Engine           # ğŸ­ æ ¸å¿ƒæ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ Workflow Parser      # å·¥ä½œæµè§£æå™¨
â”‚   â”œâ”€â”€ Execution Runtime    # æ‰§è¡Œè¿è¡Œæ—¶
â”‚   â”œâ”€â”€ State Manager        # çŠ¶æ€ç®¡ç†å™¨
â”‚   â””â”€â”€ Error Handler        # é”™è¯¯å¤„ç†å™¨
â”œâ”€â”€ AI Enhancement       # ğŸ¤– AIå¢å¼ºæ¨¡å—
â”‚   â”œâ”€â”€ Decision Engine     # å†³ç­–å¼•æ“
â”‚   â”œâ”€â”€ Prediction Model    # é¢„æµ‹æ¨¡å‹
â”‚   â”œâ”€â”€ Optimization Agent  # ä¼˜åŒ–ä»£ç†
â”‚   â””â”€â”€ Learning System     # å­¦ä¹ ç³»ç»Ÿ
â”œâ”€â”€ Visual Designer      # ğŸ¨ å¯è§†åŒ–è®¾è®¡å™¨
â”‚   â”œâ”€â”€ Canvas Renderer    # ç”»å¸ƒæ¸²æŸ“å™¨
â”‚   â”œâ”€â”€ Node Library       # èŠ‚ç‚¹åº“
â”‚   â”œâ”€â”€ Connection Manager  # è¿æ¥ç®¡ç†å™¨
â”‚   â””â”€â”€ Property Editor    # å±æ€§ç¼–è¾‘å™¨
â”œâ”€â”€ Monitoring System    # ğŸ“Š ç›‘æ§ç³»ç»Ÿ
â”‚   â”œâ”€â”€ Execution Tracker   # æ‰§è¡Œè¿½è¸ªå™¨
â”‚   â”œâ”€â”€ Performance Metrics # æ€§èƒ½æŒ‡æ ‡
â”‚   â”œâ”€â”€ Alert Manager      # å‘Šè­¦ç®¡ç†å™¨
â”‚   â””â”€â”€ Analytics Engine   # åˆ†æå¼•æ“
â””â”€â”€ Plugin Ecosystem    # ğŸ”Œ æ’ä»¶ç”Ÿæ€
    â”œâ”€â”€ Node Plugins       # èŠ‚ç‚¹æ’ä»¶
    â”œâ”€â”€ Connector Plugins  # è¿æ¥å™¨æ’ä»¶
    â”œâ”€â”€ Action Plugins     # åŠ¨ä½œæ’ä»¶
    â””â”€â”€ Integration Plugins# é›†æˆæ’ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```rust
use frys_workflow_engine::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆ›å»ºå·¥ä½œæµå¼•æ“
    let engine = WorkflowEngine::new(WorkflowEngineConfig {
        max_concurrent_workflows: 1000,
        max_concurrent_tasks: 100,
        execution_timeout: Duration::from_secs(3600),
        enable_ai_enhancement: true,
        enable_monitoring: true,
    }).await?;

    // å®šä¹‰å·¥ä½œæµ
    let workflow = Workflow::builder("data_processing_pipeline")
        .description("AIå¢å¼ºçš„æ•°æ®å¤„ç†æµæ°´çº¿")

        // è¾“å…¥èŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "input".to_string(),
            node_type: WorkflowNodeType::Start,
            position: Position { x: 100.0, y: 100.0 },
            data: NodeData {
                label: "æ•°æ®è¾“å…¥".to_string(),
                config: serde_json::json!({
                    "source": "database",
                    "table": "user_data"
                }),
            },
        })

        // AIåˆ†æèŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "ai_analysis".to_string(),
            node_type: WorkflowNodeType::Task,
            position: Position { x: 300.0, y: 100.0 },
            data: NodeData {
                label: "AIæƒ…æ„Ÿåˆ†æ".to_string(),
                config: serde_json::json!({
                    "model": "bert-sentiment",
                    "threshold": 0.8
                }),
            },
        })

        // å†³ç­–èŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "decision".to_string(),
            node_type: WorkflowNodeType::Decision,
            position: Position { x: 500.0, y: 100.0 },
            data: NodeData {
                label: "æƒ…æ„Ÿå†³ç­–".to_string(),
                config: serde_json::json!({
                    "condition": "sentiment_score > 0.8"
                }),
            },
        })

        // åŠ¨ä½œèŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "positive_action".to_string(),
            node_type: WorkflowNodeType::Task,
            position: Position { x: 700.0, y: 50.0 },
            data: NodeData {
                label: "ç§¯æåé¦ˆ".to_string(),
                config: serde_json::json!({
                    "action": "send_positive_email"
                }),
            },
        })

        .add_node(WorkflowNode {
            id: "negative_action".to_string(),
            node_type: WorkflowNodeType::Task,
            position: Position { x: 700.0, y: 150.0 },
            data: NodeData {
                label: "æ”¹è¿›å»ºè®®".to_string(),
                config: serde_json::json!({
                    "action": "send_improvement_email"
                }),
            },
        })

        // ç»“æŸèŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "end".to_string(),
            node_type: WorkflowNodeType::End,
            position: Position { x: 900.0, y: 100.0 },
            data: NodeData {
                label: "æµç¨‹ç»“æŸ".to_string(),
                config: serde_json::json!({}),
            },
        })

        // å®šä¹‰è¿æ¥
        .add_edge(WorkflowEdge {
            id: "input-analysis".to_string(),
            source: "input".to_string(),
            target: "ai_analysis".to_string(),
        })

        .add_edge(WorkflowEdge {
            id: "analysis-decision".to_string(),
            source: "ai_analysis".to_string(),
            target: "decision".to_string(),
        })

        .add_edge(WorkflowEdge {
            id: "decision-positive".to_string(),
            source: "decision".to_string(),
            target: "positive_action".to_string(),
            data: Some(EdgeData {
                condition: Some("sentiment_score > 0.8".to_string()),
            }),
        })

        .add_edge(WorkflowEdge {
            id: "decision-negative".to_string(),
            source: "decision".to_string(),
            target: "negative_action".to_string(),
            data: Some(EdgeData {
                condition: Some("sentiment_score <= 0.8".to_string()),
            }),
        })

        .add_edge(WorkflowEdge {
            id: "positive-end".to_string(),
            source: "positive_action".to_string(),
            target: "end".to_string(),
        })

        .add_edge(WorkflowEdge {
            id: "negative-end".to_string(),
            source: "negative_action".to_string(),
            target: "end".to_string(),
        })

        .build();

    // æ³¨å†Œå·¥ä½œæµ
    engine.register_workflow(workflow).await?;

    // å¯åŠ¨å·¥ä½œæµå®ä¾‹
    let instance = engine.start_workflow_instance(
        "data_processing_pipeline",
        serde_json::json!({
            "user_id": "user123",
            "data": "I love this product! It's amazing."
        })
    ).await?;

    println!("Workflow instance started: {}", instance.id);

    // ç›‘æ§æ‰§è¡ŒçŠ¶æ€
    let status = engine.get_instance_status(&instance.id).await?;
    println!("Current status: {:?}", status);

    Ok(())
}
```

### AIå¢å¼ºçš„å·¥ä½œæµ

```rust
// AIé©±åŠ¨çš„åŠ¨æ€å†³ç­–
let ai_decision_node = WorkflowNode {
    id: "ai_decision".to_string(),
    node_type: WorkflowNodeType::AIDecision,
    data: NodeData {
        label: "AIæ™ºèƒ½å†³ç­–".to_string(),
        config: serde_json::json!({
            "model": "decision-tree-classifier",
            "features": ["sentiment_score", "urgency_level", "customer_value"],
            "threshold": 0.85
        }),
    },
};

// é¢„æµ‹æ€§æ‰§è¡Œ
let predictive_node = WorkflowNode {
    id: "predictive_action".to_string(),
    node_type: WorkflowNodeType::PredictiveTask,
    data: NodeData {
        label: "é¢„æµ‹æ€§æ‰§è¡Œ".to_string(),
        config: serde_json::json!({
            "model": "time-series-forecast",
            "prediction_window": "7d",
            "confidence_threshold": 0.9
        }),
    },
};
```

### å®æ—¶ç›‘æ§

```rust
// è®¢é˜…å·¥ä½œæµäº‹ä»¶
engine.subscribe_events("workflow.*", |event| {
    match event.event_type.as_str() {
        "workflow.started" => {
            println!("Workflow {} started", event.instance_id);
        }
        "workflow.completed" => {
            println!("Workflow {} completed successfully", event.instance_id);
        }
        "workflow.failed" => {
            println!("Workflow {} failed: {:?}", event.instance_id, event.data);
        }
        "node.executed" => {
            let node_id = event.data["node_id"].as_str().unwrap_or("unknown");
            let duration = event.data["duration_ms"].as_u64().unwrap_or(0);
            println!("Node {} executed in {}ms", node_id, duration);
        }
        _ => {}
    }
}).await?;
```

## ğŸ¨ å¯è§†åŒ–è®¾è®¡å™¨

### å‰ç«¯é›†æˆ

```typescript
// Reactç»„ä»¶é›†æˆ
import { WorkflowDesigner } from 'frys-workflow-designer';

function App() {
  const [workflow, setWorkflow] = useState(null);

  return (
    <div style={{ height: '100vh' }}>
      <WorkflowDesigner
        workflow={workflow}
        onWorkflowChange={setWorkflow}
        nodeTypes={{
          aiInference: AIInferenceNode,
          decision: DecisionNode,
          apiCall: ApiCallNode,
          dataTransform: DataTransformNode,
        }}
        plugins={[
          'ai-enhancement',
          'performance-monitoring',
          'error-recovery',
        ]}
      />
    </div>
  );
}
```

### è‡ªå®šä¹‰èŠ‚ç‚¹å¼€å‘

```typescript
// è‡ªå®šä¹‰AIèŠ‚ç‚¹
const AINode = {
  type: 'ai-inference',
  label: 'AIæ¨ç†',
  icon: 'ğŸ¤–',
  category: 'AI',
  inputs: [
    { id: 'input', label: 'è¾“å…¥æ•°æ®', type: 'any' }
  ],
  outputs: [
    { id: 'output', label: 'æ¨ç†ç»“æœ', type: 'any' },
    { id: 'confidence', label: 'ç½®ä¿¡åº¦', type: 'number' }
  ],
  configSchema: {
    model: { type: 'string', required: true },
    parameters: { type: 'object' },
    threshold: { type: 'number', default: 0.8 }
  },
  execute: async (inputs, config) => {
    // è°ƒç”¨AIæ¨ç†æœåŠ¡
    const result = await aiService.infer(config.model, inputs.input, config.parameters);

    return {
      output: result.data,
      confidence: result.confidence
    };
  }
};
```

## ğŸ“Š ç›‘æ§å’Œåˆ†æ

### æ‰§è¡ŒæŒ‡æ ‡æ”¶é›†

```rust
// è‡ªåŠ¨æ”¶é›†çš„æŒ‡æ ‡
let metrics = engine.get_metrics().await?;

println!("Active workflows: {}", metrics.active_workflows);
println!("Completed workflows: {}", metrics.completed_workflows);
println!("Failed workflows: {}", metrics.failed_workflows);
println!("Average execution time: {}ms", metrics.avg_execution_time);
println!("Success rate: {:.2}%", metrics.success_rate * 100.0);
println!("Throughput: {:.2} workflows/min", metrics.throughput_per_minute);
```

### æ€§èƒ½åˆ†æ

```rust
// å·¥ä½œæµæ€§èƒ½åˆ†æ
let analysis = engine.analyze_performance("my-workflow").await?;

println!("Bottlenecks:");
for bottleneck in analysis.bottlenecks {
    println!("  - {}: {}ms (avg)", bottleneck.node_id, bottleneck.avg_duration);
}

println!("Optimization suggestions:");
for suggestion in analysis.suggestions {
    println!("  - {}", suggestion);
}
```

### å®æ—¶ä»ªè¡¨æ¿

```rust
// åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿
let dashboard = MonitoringDashboard::new()
    .add_chart("workflow_throughput", ChartType::Line, "Workflows per Minute")
    .add_chart("execution_time", ChartType::Histogram, "Execution Time Distribution")
    .add_chart("error_rate", ChartType::Gauge, "Error Rate")
    .add_alert("high_error_rate", "error_rate > 0.05", AlertSeverity::Warning)
    .build();

engine.register_dashboard(dashboard).await?;
```

## ğŸ”§ æ’ä»¶ç³»ç»Ÿ

### èŠ‚ç‚¹æ’ä»¶å¼€å‘

```rust
#[async_trait]
pub trait WorkflowNodePlugin: Send + Sync {
    fn node_type(&self) -> &str;
    fn name(&self) -> &str;
    fn description(&self) -> &str;

    async fn validate_config(&self, config: &serde_json::Value) -> Result<()>;
    async fn execute(&self, context: ExecutionContext) -> Result<serde_json::Value>;
    fn input_schema(&self) -> serde_json::Value;
    fn output_schema(&self) -> serde_json::Value;
}

// HTTPè¯·æ±‚èŠ‚ç‚¹æ’ä»¶
pub struct HttpRequestNode {
    client: reqwest::Client,
}

#[async_trait]
impl WorkflowNodePlugin for HttpRequestNode {
    fn node_type(&self) -> &str { "http-request" }
    fn name(&self) -> &str { "HTTP Request" }
    fn description(&self) -> &str { "Make HTTP requests to external APIs" }

    async fn execute(&self, context: ExecutionContext) -> Result<serde_json::Value> {
        let config = context.config.as_object().unwrap();

        let method = config["method"].as_str().unwrap_or("GET");
        let url = config["url"].as_str().unwrap();
        let headers = config["headers"].as_object().unwrap_or(&serde_json::Map::new());
        let body = config["body"].as_str();

        let mut request = self.client.request(
            reqwest::Method::from_bytes(method.as_bytes())?,
            url
        );

        for (key, value) in headers {
            if let Some(value_str) = value.as_str() {
                request = request.header(key, value_str);
            }
        }

        if let Some(body) = body {
            request = request.body(body.to_string());
        }

        let response = request.send().await?;
        let status = response.status();
        let body = response.text().await?;

        Ok(serde_json::json!({
            "status": status.as_u16(),
            "headers": {}, // Simplified
            "body": body
        }))
    }
}
```

### è¿æ¥å™¨æ’ä»¶

```rust
#[async_trait]
pub trait WorkflowConnectorPlugin: Send + Sync {
    fn connector_type(&self) -> &str;
    async fn connect(&self, source: &WorkflowNode, target: &WorkflowNode) -> Result<Connection>;
    async fn transfer(&self, connection: &Connection, data: serde_json::Value) -> Result<serde_json::Value>;
}

// æ¡ä»¶è¿æ¥å™¨
pub struct ConditionalConnector;

#[async_trait]
impl WorkflowConnectorPlugin for ConditionalConnector {
    fn connector_type(&self) -> &str { "conditional" }

    async fn transfer(&self, connection: &Connection, data: serde_json::Value) -> Result<serde_json::Value> {
        let condition = connection.config["condition"].as_str()
            .ok_or_else(|| WorkflowError::InvalidConfiguration("Missing condition".to_string()))?;

        // ç®€å•çš„æ¡ä»¶è¯„ä¼° (ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥ä½¿ç”¨æ›´å¼ºå¤§çš„è¡¨è¾¾å¼å¼•æ“)
        let result = evaluate_condition(condition, &data)?;

        if result {
            Ok(data)
        } else {
            Err(WorkflowError::ConditionNotMet)
        }
    }
}
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_simple_workflow_execution() {
        let engine = WorkflowEngine::new(Default::default()).await.unwrap();

        let workflow = create_test_workflow();
        engine.register_workflow(workflow).await.unwrap();

        let instance = engine.start_workflow_instance(
            "test-workflow",
            serde_json::json!({"input": "test"})
        ).await.unwrap();

        // ç­‰å¾…æ‰§è¡Œå®Œæˆ
        tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

        let status = engine.get_instance_status(&instance.id).await.unwrap();
        assert_eq!(status, WorkflowStatus::Completed);
    }

    #[tokio::test]
    async fn test_ai_enhanced_decision() {
        let engine = WorkflowEngine::new(WorkflowEngineConfig {
            enable_ai_enhancement: true,
            ..Default::default()
        }).await.unwrap();

        let workflow = create_ai_workflow();
        engine.register_workflow(workflow).await.unwrap();

        let instance = engine.start_workflow_instance(
            "ai-workflow",
            serde_json::json!({"text": "This product is amazing!"})
        ).await.unwrap();

        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

        let result = engine.get_instance_result(&instance.id).await.unwrap();
        let sentiment = result["sentiment"].as_str().unwrap();
        assert_eq!(sentiment, "positive");
    }
}
```

### é›†æˆæµ‹è¯•

```rust
#[cfg(test)]
mod integration_tests {
    use super::*;
    use frys_kernel::FrysKernel;

    #[tokio::test]
    async fn test_full_workflow_lifecycle() {
        // å¯åŠ¨å®Œæ•´ç³»ç»Ÿ
        let kernel = FrysKernel::new(Default::default()).await.unwrap();
        kernel.load_plugin("workflow-engine").await.unwrap();

        let engine = WorkflowEngine::from_kernel(&kernel).await.unwrap();

        // åˆ›å»ºå¤æ‚çš„å·¥ä½œæµ
        let workflow = create_complex_workflow();
        engine.register_workflow(workflow).await.unwrap();

        // å¹¶å‘æ‰§è¡Œå¤šä¸ªå®ä¾‹
        let mut handles = vec![];
        for i in 0..10 {
            let engine_clone = engine.clone();
            let handle = tokio::spawn(async move {
                let instance = engine_clone.start_workflow_instance(
                    "complex-workflow",
                    serde_json::json!({ "iteration": i })
                ).await.unwrap();

                // ç›‘æ§æ‰§è¡Œè¿›åº¦
                loop {
                    let status = engine_clone.get_instance_status(&instance.id).await.unwrap();
                    if status == WorkflowStatus::Completed || status == WorkflowStatus::Failed {
                        break;
                    }
                    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
                }

                instance.id
            });
            handles.push(handle);
        }

        // ç­‰å¾…æ‰€æœ‰å®ä¾‹å®Œæˆ
        for handle in handles {
            let instance_id = handle.await.unwrap();
            let status = engine.get_instance_status(&instance_id).await.unwrap();
            assert_eq!(status, WorkflowStatus::Completed);
        }

        kernel.shutdown().await.unwrap();
    }
}
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### åŸºå‡†æµ‹è¯•ç»“æœ

| åœºæ™¯ | å¹¶å‘æ•° | ååé‡ | å¹³å‡å»¶è¿Ÿ | P95å»¶è¿Ÿ | P99å»¶è¿Ÿ |
|------|--------|--------|----------|---------|---------|
| ç®€å•å·¥ä½œæµ | 100 | 1250 ops/s | 45ms | 120ms | 200ms |
| AIå¢å¼ºå·¥ä½œæµ | 50 | 380 ops/s | 180ms | 450ms | 800ms |
| å¤æ‚ä¸šåŠ¡æµç¨‹ | 25 | 180 ops/s | 320ms | 750ms | 1200ms |

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

```rust
// æ€§èƒ½é…ç½®è°ƒä¼˜
let config = WorkflowEngineConfig {
    // å†…å­˜ä¼˜åŒ–
    max_concurrent_workflows: 1000,
    max_concurrent_tasks: 100,
    workflow_cache_size: 100,

    // æ‰§è¡Œä¼˜åŒ–
    enable_parallel_execution: true,
    enable_ai_caching: true,
    enable_result_caching: true,

    // ç›‘æ§ä¼˜åŒ–
    enable_metrics: true,
    metrics_interval: Duration::from_secs(5),
    enable_tracing: true,
};
```

## ğŸš€ éƒ¨ç½²å’Œæ‰©å±•

### å•æœºéƒ¨ç½²

```yaml
# Docker Compose
version: '3.8'
services:
  frys-workflow-engine:
    image: frys-workflow-engine:latest
    ports:
      - "8080:8080"
    environment:
      - FRYS_WORKFLOW_MAX_CONCURRENT=1000
      - FRYS_AI_ENABLED=true
    volumes:
      - ./config:/app/config:ro
```

### é›†ç¾¤éƒ¨ç½²

```yaml
# Kubernetes Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frys-workflow-engine
spec:
  replicas: 3
  selector:
    matchLabels:
      app: workflow-engine
  template:
    spec:
      containers:
      - name: workflow-engine
        image: frys-workflow-engine:latest
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        env:
        - name: FRYS_WORKFLOW_MAX_CONCURRENT
          value: "2000"
        - name: FRYS_AI_ENABLED
          value: "true"
        ports:
        - containerPort: 8080
```

### æ°´å¹³æ‰©å±•

```rust
// è‡ªåŠ¨æ‰©ç¼©å®¹é…ç½®
let scaler = AutoScaler::new(AutoScalerConfig {
    min_instances: 3,
    max_instances: 20,
    scale_up_threshold: 0.8,    // CPU > 80%
    scale_down_threshold: 0.3,  // CPU < 30%
    cooldown_period: Duration::from_secs(300),
    metrics_provider: prometheus_metrics,
}).await?;
```

## ğŸ”§ é…ç½®å’Œè°ƒä¼˜

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# åŸºç¡€é…ç½®
export FRYS_WORKFLOW_MAX_CONCURRENT=1000
export FRYS_WORKFLOW_EXECUTION_TIMEOUT=3600
export FRYS_WORKFLOW_CACHE_SIZE=100

# AIå¢å¼ºé…ç½®
export FRYS_AI_ENABLED=true
export FRYS_AI_MODEL_CACHE_SIZE=50
export FRYS_AI_INFERENCE_TIMEOUT=300

# ç›‘æ§é…ç½®
export FRYS_MONITORING_ENABLED=true
export FRYS_METRICS_INTERVAL=5
export FRYS_TRACING_ENABLED=true

# æ’ä»¶é…ç½®
export FRYS_PLUGIN_PATHS="/app/plugins"
export FRYS_PLUGIN_AUTO_LOAD=true
```

### åŠ¨æ€é…ç½®

```rust
// è¿è¡Œæ—¶é…ç½®æ›´æ–°
engine.update_config(WorkflowConfigUpdate {
    max_concurrent_workflows: Some(1500),
    enable_ai_enhancement: Some(false),
    monitoring_level: Some(MonitoringLevel::Detailed),
}).await?;
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### å·¥ä½œæµæ‰§è¡Œå¡ä½
```
åŸå› : èŠ‚ç‚¹ä¾èµ–æœªæ»¡è¶³æˆ–æ­»é”
è§£å†³:
1. æ£€æŸ¥å·¥ä½œæµå®šä¹‰çš„ä¾èµ–å…³ç³»
2. å¯ç”¨æ­»é”æ£€æµ‹: --enable-deadlock-detection true
3. å¢åŠ æ‰§è¡Œè¶…æ—¶: --execution-timeout 7200
```

#### AIæ¨ç†å¤±è´¥
```
åŸå› : æ¨¡å‹åŠ è½½å¤±è´¥æˆ–æ¨ç†è¶…æ—¶
è§£å†³:
1. æ£€æŸ¥AIæœåŠ¡è¿æ¥: --ai-service-url http://ai-service:8080
2. å¢åŠ æ¨ç†è¶…æ—¶: --ai-inference-timeout 600
3. å¯ç”¨é‡è¯•æœºåˆ¶: --ai-retry-enabled true
```

#### å†…å­˜ä¸è¶³
```
åŸå› : å¹¶å‘å·¥ä½œæµè¿‡å¤šæˆ–å†…å­˜æ³„æ¼
è§£å†³:
1. å‡å°‘å¹¶å‘æ•°: --max-concurrent-workflows 500
2. å¯ç”¨å†…å­˜ç›‘æ§: --enable-memory-monitoring true
3. å¢åŠ å®ä¾‹å†…å­˜: resources.limits.memory=4Gi
```

## ğŸ“š APIå‚è€ƒ

### REST API

```http
# åˆ›å»ºå·¥ä½œæµ
POST /api/v1/workflows
Content-Type: application/json

{
  "name": "my-workflow",
  "nodes": [...],
  "edges": [...]
}

# å¯åŠ¨å·¥ä½œæµå®ä¾‹
POST /api/v1/workflows/{workflow-id}/instances
Content-Type: application/json

{
  "context": {...}
}

# è·å–å®ä¾‹çŠ¶æ€
GET /api/v1/instances/{instance-id}

# è·å–æ‰§è¡Œç»“æœ
GET /api/v1/instances/{instance-id}/results
```

### WebSocket API

```javascript
// è¿æ¥åˆ°å·¥ä½œæµå¼•æ“
const ws = new WebSocket('ws://localhost:8080/ws/workflows');

// è®¢é˜…å·¥ä½œæµäº‹ä»¶
ws.send(JSON.stringify({
  type: 'subscribe',
  pattern: 'workflow.*'
}));

// æ¥æ”¶äº‹ä»¶
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Workflow event:', data);
};
```

## ğŸ¤ è´¡çŒ®

### å¼€å‘æŒ‡å—
1. Fork æœ¬ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature/new-workflow-node`
3. ç¼–å†™ä»£ç å’Œæµ‹è¯•
4. è¿è¡Œæµ‹è¯•: `cargo test`
5. æäº¤PR

### æ’ä»¶å¼€å‘
1. å®ç° `WorkflowNodePlugin` trait
2. æ·»åŠ æ’ä»¶é…ç½®æ–‡ä»¶
3. ç¼–å†™æ’ä»¶æ–‡æ¡£
4. æäº¤åˆ°æ’ä»¶ä»“åº“

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](../../LICENSE) æ–‡ä»¶