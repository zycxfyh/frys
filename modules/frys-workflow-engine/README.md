# Frys Workflow Engine (frys-workflow-engine)

Frys Workflow Engine æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒä¸šåŠ¡å¼•æ“ï¼Œæä¾›äº†é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„å·¥ä½œæµæ‰§è¡Œèƒ½åŠ›ã€‚å®ƒæ”¯æŒAIå¢å¼ºçš„å†³ç­–ã€å¹¶å‘æ‰§è¡Œã€å®æ—¶ç›‘æ§å’Œå¯è§†åŒ–è®¾è®¡ã€‚

## ğŸ¯ è®¾è®¡ç†å¿µ

**AIå¢å¼ºçš„å·¥ä½œæµå¼•æ“ï¼Œé‡æ–°å®šä¹‰è‡ªåŠ¨åŒ–æµç¨‹çš„æ‰§è¡Œæ–¹å¼**

### æ ¸å¿ƒç‰¹æ€§
- **ğŸ¤– AIåŸç”Ÿ**: å†…ç½®AIæ¨ç†å’Œå†³ç­–èƒ½åŠ›
- **âš¡ é«˜å¹¶å‘**: æ”¯æŒæ•°ä¸‡ä¸ªå¹¶å‘å·¥ä½œæµå®ä¾‹
- **ğŸ¨ å¯è§†åŒ–**: æ‹–æ‹½å¼å·¥ä½œæµè®¾è®¡å™¨
- **ğŸ“Š å®æ—¶ç›‘æ§**: å®Œæ•´çš„æ‰§è¡ŒçŠ¶æ€è¿½è¸ª
- **ğŸ”„ åŠ¨æ€è°ƒæ•´**: è¿è¡Œæ—¶å·¥ä½œæµä¿®æ”¹
- **ğŸ›¡ï¸ å®¹é”™æ€§**: è‡ªåŠ¨æ•…éšœæ¢å¤å’Œè¡¥å¿æœºåˆ¶

### æ¶æ„ä¼˜åŠ¿
- **æ€§èƒ½æè‡´**: Rustå®ç°çš„åŸç”Ÿæ€§èƒ½
- **æ‰©å±•æ— é™**: æ’ä»¶åŒ–èŠ‚ç‚¹å’Œè¿æ¥å™¨
- **æ™ºèƒ½å†³ç­–**: AIé©±åŠ¨çš„è·¯å¾„é€‰æ‹©å’Œä¼˜åŒ–
- **ç›‘æ§å…¨é¢**: ç«¯åˆ°ç«¯çš„å¯è§‚æµ‹æ€§
- **å¼€å‘å‹å¥½**: å£°æ˜å¼APIå’Œå¯è§†åŒ–å·¥å…·

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
frys-workflow-engine/
â”œâ”€â”€ Core Engine           # ğŸ­ æ ¸å¿ƒæ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ Workflow Parser      # å·¥ä½œæµè§£æå™¨
â”‚   â”œâ”€â”€ Execution Runtime    # æ‰§è¡Œè¿è¡Œæ—¶
â”‚   â”œâ”€â”€ State Manager        # çŠ¶æ€ç®¡ç†å™¨
â”‚   â””â”€â”€ Error Handler        # é”™è¯¯å¤„ç†å™¨
â”œâ”€â”€ AI Enhancement       # ğŸ¤– AIå¢å¼ºæ¨¡å—
â”‚   â”œâ”€â”€ Decision Engine     # å†³ç­–å¼•æ“
â”‚   â”œâ”€â”€ Prediction Model    # é¢„æµ‹æ¨¡å‹
â”‚   â”œâ”€â”€ Optimization Agent  # ä¼˜åŒ–ä»£ç†
â”‚   â””â”€â”€ Learning System     # å­¦ä¹ ç³»ç»Ÿ
â”œâ”€â”€ Visual Designer      # ğŸ¨ å¯è§†åŒ–è®¾è®¡å™¨
â”‚   â”œâ”€â”€ Canvas Renderer    # ç”»å¸ƒæ¸²æŸ“å™¨
â”‚   â”œâ”€â”€ Node Library       # èŠ‚ç‚¹åº“
â”‚   â”œâ”€â”€ Connection Manager  # è¿æ¥ç®¡ç†å™¨
â”‚   â””â”€â”€ Property Editor    # å±æ€§ç¼–è¾‘å™¨
â”œâ”€â”€ Monitoring System    # ğŸ“Š ç›‘æ§ç³»ç»Ÿ
â”‚   â”œâ”€â”€ Execution Tracker   # æ‰§è¡Œè¿½è¸ªå™¨
â”‚   â”œâ”€â”€ Performance Metrics # æ€§èƒ½æŒ‡æ ‡
â”‚   â”œâ”€â”€ Alert Manager      # å‘Šè­¦ç®¡ç†å™¨
â”‚   â””â”€â”€ Analytics Engine   # åˆ†æå¼•æ“
â””â”€â”€ Plugin Ecosystem    # ğŸ”Œ æ’ä»¶ç”Ÿæ€
    â”œâ”€â”€ Node Plugins       # èŠ‚ç‚¹æ’ä»¶
    â”œâ”€â”€ Connector Plugins  # è¿æ¥å™¨æ’ä»¶
    â”œâ”€â”€ Action Plugins     # åŠ¨ä½œæ’ä»¶
    â””â”€â”€ Integration Plugins# é›†æˆæ’ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```rust
use frys_workflow_engine::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆ›å»ºå·¥ä½œæµå¼•æ“
    let engine = WorkflowEngine::new(WorkflowEngineConfig {
        max_concurrent_workflows: 1000,
        max_concurrent_tasks: 100,
        execution_timeout: Duration::from_secs(3600),
        enable_ai_enhancement: true,
        enable_monitoring: true,
    }).await?;

    // å®šä¹‰å·¥ä½œæµ
    let workflow = Workflow::builder("data_processing_pipeline")
        .description("AIå¢å¼ºçš„æ•°æ®å¤„ç†æµæ°´çº¿")

        // è¾“å…¥èŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "input".to_string(),
            node_type: WorkflowNodeType::Start,
            position: Position { x: 100.0, y: 100.0 },
            data: NodeData {
                label: "æ•°æ®è¾“å…¥".to_string(),
                config: serde_json::json!({
                    "source": "database",
                    "table": "user_data"
                }),
            },
        })

        // AIåˆ†æèŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "ai_analysis".to_string(),
            node_type: WorkflowNodeType::Task,
            position: Position { x: 300.0, y: 100.0 },
            data: NodeData {
                label: "AIæƒ…æ„Ÿåˆ†æ".to_string(),
                config: serde_json::json!({
                    "model": "bert-sentiment",
                    "threshold": 0.8
                }),
            },
        })

        // å†³ç­–èŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "decision".to_string(),
            node_type: WorkflowNodeType::Decision,
            position: Position { x: 500.0, y: 100.0 },
            data: NodeData {
                label: "æƒ…æ„Ÿå†³ç­–".to_string(),
                config: serde_json::json!({
                    "condition": "sentiment_score > 0.8"
                }),
            },
        })

        // åŠ¨ä½œèŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "positive_action".to_string(),
            node_type: WorkflowNodeType::Task,
            position: Position { x: 700.0, y: 50.0 },
            data: NodeData {
                label: "ç§¯æåé¦ˆ".to_string(),
                config: serde_json::json!({
                    "action": "send_positive_email"
                }),
            },
        })

        .add_node(WorkflowNode {
            id: "negative_action".to_string(),
            node_type: WorkflowNodeType::Task,
            position: Position { x: 700.0, y: 150.0 },
            data: NodeData {
                label: "æ”¹è¿›å»ºè®®".to_string(),
                config: serde_json::json!({
                    "action": "send_improvement_email"
                }),
            },
        })

        // ç»“æŸèŠ‚ç‚¹
        .add_node(WorkflowNode {
            id: "end".to_string(),
            node_type: WorkflowNodeType::End,
            position: Position { x: 900.0, y: 100.0 },
            data: NodeData {
                label: "æµç¨‹ç»“æŸ".to_string(),
                config: serde_json::json!({}),
            },
        })

        // å®šä¹‰è¿æ¥
        .add_edge(WorkflowEdge {
            id: "input-analysis".to_string(),
            source: "input".to_string(),
            target: "ai_analysis".to_string(),
        })

        .add_edge(WorkflowEdge {
            id: "analysis-decision".to_string(),
            source: "ai_analysis".to_string(),
            target: "decision".to_string(),
        })

        .add_edge(WorkflowEdge {
            id: "decision-positive".to_string(),
            source: "decision".to_string(),
            target: "positive_action".to_string(),
            data: Some(EdgeData {
                condition: Some("sentiment_score > 0.8".to_string()),
            }),
        })

        .add_edge(WorkflowEdge {
            id: "decision-negative".to_string(),
            source: "decision".to_string(),
            target: "negative_action".to_string(),
            data: Some(EdgeData {
                condition: Some("sentiment_score <= 0.8".to_string()),
            }),
        })

        .add_edge(WorkflowEdge {
            id: "positive-end".to_string(),
            source: "positive_action".to_string(),
            target: "end".to_string(),
        })

        .add_edge(WorkflowEdge {
            id: "negative-end".to_string(),
            source: "negative_action".to_string(),
            target: "end".to_string(),
        })

        .build();

    // æ³¨å†Œå·¥ä½œæµ
    engine.register_workflow(workflow).await?;

    // å¯åŠ¨å·¥ä½œæµå®ä¾‹
    let instance = engine.start_workflow_instance(
        "data_processing_pipeline",
        serde_json::json!({
            "user_id": "user123",
            "data": "I love this product! It's amazing."
        })
    ).await?;

    println!("Workflow instance started: {}", instance.id);

    // ç›‘æ§æ‰§è¡ŒçŠ¶æ€
    let status = engine.get_instance_status(&instance.id).await?;
    println!("Current status: {:?}", status);

    Ok(())
}
```

### AIå¢å¼ºçš„å·¥ä½œæµ

```rust
// AIé©±åŠ¨çš„åŠ¨æ€å†³ç­–
let ai_decision_node = WorkflowNode {
    id: "ai_decision".to_string(),
    node_type: WorkflowNodeType::AIDecision,
    data: NodeData {
        label: "AIæ™ºèƒ½å†³ç­–".to_string(),
        config: serde_json::json!({
            "model": "decision-tree-classifier",
            "features": ["sentiment_score", "urgency_level", "customer_value"],
            "threshold": 0.85
        }),
    },
};

// é¢„æµ‹æ€§æ‰§è¡Œ
let predictive_node = WorkflowNode {
    id: "predictive_action".to_string(),
    node_type: WorkflowNodeType::PredictiveTask,
    data: NodeData {
        label: "é¢„æµ‹æ€§æ‰§è¡Œ".to_string(),
        config: serde_json::json!({
            "model": "time-series-forecast",
            "prediction_window": "7d",
            "confidence_threshold": 0.9
        }),
    },
};
```

### å®æ—¶ç›‘æ§

```rust
// è®¢é˜…å·¥ä½œæµäº‹ä»¶
engine.subscribe_events("workflow.*", |event| {
    match event.event_type.as_str() {
        "workflow.started" => {
            println!("Workflow {} started", event.instance_id);
        }
        "workflow.completed" => {
            println!("Workflow {} completed successfully", event.instance_id);
        }
        "workflow.failed" => {
            println!("Workflow {} failed: {:?}", event.instance_id, event.data);
        }
        "node.executed" => {
            let node_id = event.data["node_id"].as_str().unwrap_or("unknown");
            let duration = event.data["duration_ms"].as_u64().unwrap_or(0);
            println!("Node {} executed in {}ms", node_id, duration);
        }
        _ => {}
    }
}).await?;
```

## ğŸ¨ å¯è§†åŒ–è®¾è®¡å™¨

### å‰ç«¯é›†æˆ

```typescript
// Reactç»„ä»¶é›†æˆ
import { WorkflowDesigner } from 'frys-workflow-designer';

function App() {
  const [workflow, setWorkflow] = useState(null);

  return (
    <div style={{ height: '100vh' }}>
      <WorkflowDesigner
        workflow={workflow}
        onWorkflowChange={setWorkflow}
        nodeTypes={{
          aiInference: AIInferenceNode,
          decision: DecisionNode,
          apiCall: ApiCallNode,
          dataTransform: DataTransformNode,
        }}
        plugins={[
          'ai-enhancement',
          'performance-monitoring',
          'error-recovery',
        ]}
      />
    </div>
  );
}
```

### è‡ªå®šä¹‰èŠ‚ç‚¹å¼€å‘

```typescript
// è‡ªå®šä¹‰AIèŠ‚ç‚¹
const AINode = {
  type: 'ai-inference',
  label: 'AIæ¨ç†',
  icon: 'ğŸ¤–',
  category: 'AI',
  inputs: [
    { id: 'input', label: 'è¾“å…¥æ•°æ®', type: 'any' }
  ],
  outputs: [
    { id: 'output', label: 'æ¨ç†ç»“æœ', type: 'any' },
    { id: 'confidence', label: 'ç½®ä¿¡åº¦', type: 'number' }
  ],
  configSchema: {
    model: { type: 'string', required: true },
    parameters: { type: 'object' },
    threshold: { type: 'number', default: 0.8 }
  },
  execute: async (inputs, config) => {
    // è°ƒç”¨AIæ¨ç†æœåŠ¡
    const result = await aiService.infer(config.model, inputs.input, config.parameters);

    return {
      output: result.data,
      confidence: result.confidence
    };
  }
};
```

## ğŸ“Š ç›‘æ§å’Œåˆ†æ

### æ‰§è¡ŒæŒ‡æ ‡æ”¶é›†

```rust
// è‡ªåŠ¨æ”¶é›†çš„æŒ‡æ ‡
let metrics = engine.get_metrics().await?;

println!("Active workflows: {}", metrics.active_workflows);
println!("Completed workflows: {}", metrics.completed_workflows);
println!("Failed workflows: {}", metrics.failed_workflows);
println!("Average execution time: {}ms", metrics.avg_execution_time);
println!("Success rate: {:.2}%", metrics.success_rate * 100.0);
println!("Throughput: {:.2} workflows/min", metrics.throughput_per_minute);
```

### æ€§èƒ½åˆ†æ

```rust
// å·¥ä½œæµæ€§èƒ½åˆ†æ
let analysis = engine.analyze_performance("my-workflow").await?;

println!("Bottlenecks:");
for bottleneck in analysis.bottlenecks {
    println!("  - {}: {}ms (avg)", bottleneck.node_id, bottleneck.avg_duration);
}

println!("Optimization suggestions:");
for suggestion in analysis.suggestions {
    println!("  - {}", suggestion);
}
```

### å®æ—¶ä»ªè¡¨æ¿

```rust
// åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿
let dashboard = MonitoringDashboard::new()
    .add_chart("workflow_throughput", ChartType::Line, "Workflows per Minute")
    .add_chart("execution_time", ChartType::Histogram, "Execution Time Distribution")
    .add_chart("error_rate", ChartType::Gauge, "Error Rate")
    .add_alert("high_error_rate", "error_rate > 0.05", AlertSeverity::Warning)
    .build();

engine.register_dashboard(dashboard).await?;
```

## ğŸ”§ æ’ä»¶ç³»ç»Ÿ

### èŠ‚ç‚¹æ’ä»¶å¼€å‘

```rust
#[async_trait]
pub trait WorkflowNodePlugin: Send + Sync {
    fn node_type(&self) -> &str;
    fn name(&self) -> &str;
    fn description(&self) -> &str;

    async fn validate_config(&self, config: &serde_json::Value) -> Result<()>;
    async fn execute(&self, context: ExecutionContext) -> Result<serde_json::Value>;
    fn input_schema(&self) -> serde_json::Value;
    fn output_schema(&self) -> serde_json::Value;
}

// HTTPè¯·æ±‚èŠ‚ç‚¹æ’ä»¶
pub struct HttpRequestNode {
    client: reqwest::Client,
}

#[async_trait]
impl WorkflowNodePlugin for HttpRequestNode {
    fn node_type(&self) -> &str { "http-request" }
    fn name(&self) -> &str { "HTTP Request" }
    fn description(&self) -> &str { "Make HTTP requests to external APIs" }

    async fn execute(&self, context: ExecutionContext) -> Result<serde_json::Value> {
        let config = context.config.as_object().unwrap();

        let method = config["method"].as_str().unwrap_or("GET");
        let url = config["url"].as_str().unwrap();
        let headers = config["headers"].as_object().unwrap_or(&serde_json::Map::new());
        let body = config["body"].as_str();

        let mut request = self.client.request(
            reqwest::Method::from_bytes(method.as_bytes())?,
            url
        );

        for (key, value) in headers {
            if let Some(value_str) = value.as_str() {
                request = request.header(key, value_str);
            }
        }

        if let Some(body) = body {
            request = request.body(body.to_string());
        }

        let response = request.send().await?;
        let status = response.status();
        let body = response.text().await?;

        Ok(serde_json::json!({
            "status": status.as_u16(),
            "headers": {}, // Simplified
            "body": body
        }))
    }
}
```

### è¿æ¥å™¨æ’ä»¶

```rust
#[async_trait]
pub trait WorkflowConnectorPlugin: Send + Sync {
    fn connector_type(&self) -> &str;
    async fn connect(&self, source: &WorkflowNode, target: &WorkflowNode) -> Result<Connection>;
    async fn transfer(&self, connection: &Connection, data: serde_json::Value) -> Result<serde_json::Value>;
}

// æ¡ä»¶è¿æ¥å™¨
pub struct ConditionalConnector;

#[async_trait]
impl WorkflowConnectorPlugin for ConditionalConnector {
    fn connector_type(&self) -> &str { "conditional" }

    async fn transfer(&self, connection: &Connection, data: serde_json::Value) -> Result<serde_json::Value> {
        let condition = connection.config["condition"].as_str()
            .ok_or_else(|| WorkflowError::InvalidConfiguration("Missing condition".to_string()))?;

        // ç®€å•çš„æ¡ä»¶è¯„ä¼° (ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥ä½¿ç”¨æ›´å¼ºå¤§çš„è¡¨è¾¾å¼å¼•æ“)
        let result = evaluate_condition(condition, &data)?;

        if result {
            Ok(data)
        } else {
            Err(WorkflowError::ConditionNotMet)
        }
    }
}
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_simple_workflow_execution() {
        let engine = WorkflowEngine::new(Default::default()).await.unwrap();

        let workflow = create_test_workflow();
        engine.register_workflow(workflow).await.unwrap();

        let instance = engine.start_workflow_instance(
            "test-workflow",
            serde_json::json!({"input": "test"})
        ).await.unwrap();

        // ç­‰å¾…æ‰§è¡Œå®Œæˆ
        tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

        let status = engine.get_instance_status(&instance.id).await.unwrap();
        assert_eq!(status, WorkflowStatus::Completed);
    }

    #[tokio::test]
    async fn test_ai_enhanced_decision() {
        let engine = WorkflowEngine::new(WorkflowEngineConfig {
            enable_ai_enhancement: true,
            ..Default::default()
        }).await.unwrap();

        let workflow = create_ai_workflow();
        engine.register_workflow(workflow).await.unwrap();

        let instance = engine.start_workflow_instance(
            "ai-workflow",
            serde_json::json!({"text": "This product is amazing!"})
        ).await.unwrap();

        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

        let result = engine.get_instance_result(&instance.id).await.unwrap();
        let sentiment = result["sentiment"].as_str().unwrap();
        assert_eq!(sentiment, "positive");
    }
}
```

### é›†æˆæµ‹è¯•

```rust
#[cfg(test)]
mod integration_tests {
    use super::*;
    use frys_kernel::FrysKernel;

    #[tokio::test]
    async fn test_full_workflow_lifecycle() {
        // å¯åŠ¨å®Œæ•´ç³»ç»Ÿ
        let kernel = FrysKernel::new(Default::default()).await.unwrap();
        kernel.load_plugin("workflow-engine").await.unwrap();

        let engine = WorkflowEngine::from_kernel(&kernel).await.unwrap();

        // åˆ›å»ºå¤æ‚çš„å·¥ä½œæµ
        let workflow = create_complex_workflow();
        engine.register_workflow(workflow).await.unwrap();

        // å¹¶å‘æ‰§è¡Œå¤šä¸ªå®ä¾‹
        let mut handles = vec![];
        for i in 0..10 {
            let engine_clone = engine.clone();
            let handle = tokio::spawn(async move {
                let instance = engine_clone.start_workflow_instance(
                    "complex-workflow",
                    serde_json::json!({ "iteration": i })
                ).await.unwrap();

                // ç›‘æ§æ‰§è¡Œè¿›åº¦
                loop {
                    let status = engine_clone.get_instance_status(&instance.id).await.unwrap();
                    if status == WorkflowStatus::Completed || status == WorkflowStatus::Failed {
                        break;
                    }
                    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
                }

                instance.id
            });
            handles.push(handle);
        }

        // ç­‰å¾…æ‰€æœ‰å®ä¾‹å®Œæˆ
        for handle in handles {
            let instance_id = handle.await.unwrap();
            let status = engine.get_instance_status(&instance_id).await.unwrap();
            assert_eq!(status, WorkflowStatus::Completed);
        }

        kernel.shutdown().await.unwrap();
    }
}
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### åŸºå‡†æµ‹è¯•ç»“æœ

| åœºæ™¯ | å¹¶å‘æ•° | ååé‡ | å¹³å‡å»¶è¿Ÿ | P95å»¶è¿Ÿ | P99å»¶è¿Ÿ |
|------|--------|--------|----------|---------|---------|
| ç®€å•å·¥ä½œæµ | 100 | 1250 ops/s | 45ms | 120ms | 200ms |
| AIå¢å¼ºå·¥ä½œæµ | 50 | 380 ops/s | 180ms | 450ms | 800ms |
| å¤æ‚ä¸šåŠ¡æµç¨‹ | 25 | 180 ops/s | 320ms | 750ms | 1200ms |

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

```rust
// æ€§èƒ½é…ç½®è°ƒä¼˜
let config = WorkflowEngineConfig {
    // å†…å­˜ä¼˜åŒ–
    max_concurrent_workflows: 1000,
    max_concurrent_tasks: 100,
    workflow_cache_size: 100,

    // æ‰§è¡Œä¼˜åŒ–
    enable_parallel_execution: true,
    enable_ai_caching: true,
    enable_result_caching: true,

    // ç›‘æ§ä¼˜åŒ–
    enable_metrics: true,
    metrics_interval: Duration::from_secs(5),
    enable_tracing: true,
};
```

## ğŸš€ éƒ¨ç½²å’Œæ‰©å±•

### å•æœºéƒ¨ç½²

```yaml
# Docker Compose
version: '3.8'
services:
  frys-workflow-engine:
    image: frys-workflow-engine:latest
    ports:
      - "8080:8080"
    environment:
      - FRYS_WORKFLOW_MAX_CONCURRENT=1000
      - FRYS_AI_ENABLED=true
    volumes:
      - ./config:/app/config:ro
```

### é›†ç¾¤éƒ¨ç½²

```yaml
# Kubernetes Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frys-workflow-engine
spec:
  replicas: 3
  selector:
    matchLabels:
      app: workflow-engine
  template:
    spec:
      containers:
      - name: workflow-engine
        image: frys-workflow-engine:latest
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        env:
        - name: FRYS_WORKFLOW_MAX_CONCURRENT
          value: "2000"
        - name: FRYS_AI_ENABLED
          value: "true"
        ports:
        - containerPort: 8080
```

### æ°´å¹³æ‰©å±•

```rust
// è‡ªåŠ¨æ‰©ç¼©å®¹é…ç½®
let scaler = AutoScaler::new(AutoScalerConfig {
    min_instances: 3,
    max_instances: 20,
    scale_up_threshold: 0.8,    // CPU > 80%
    scale_down_threshold: 0.3,  // CPU < 30%
    cooldown_period: Duration::from_secs(300),
    metrics_provider: prometheus_metrics,
}).await?;
```

## ğŸ”§ é…ç½®å’Œè°ƒä¼˜

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# åŸºç¡€é…ç½®
export FRYS_WORKFLOW_MAX_CONCURRENT=1000
export FRYS_WORKFLOW_EXECUTION_TIMEOUT=3600
export FRYS_WORKFLOW_CACHE_SIZE=100

# AIå¢å¼ºé…ç½®
export FRYS_AI_ENABLED=true
export FRYS_AI_MODEL_CACHE_SIZE=50
export FRYS_AI_INFERENCE_TIMEOUT=300

# ç›‘æ§é…ç½®
export FRYS_MONITORING_ENABLED=true
export FRYS_METRICS_INTERVAL=5
export FRYS_TRACING_ENABLED=true

# æ’ä»¶é…ç½®
export FRYS_PLUGIN_PATHS="/app/plugins"
export FRYS_PLUGIN_AUTO_LOAD=true
```

### åŠ¨æ€é…ç½®

```rust
// è¿è¡Œæ—¶é…ç½®æ›´æ–°
engine.update_config(WorkflowConfigUpdate {
    max_concurrent_workflows: Some(1500),
    enable_ai_enhancement: Some(false),
    monitoring_level: Some(MonitoringLevel::Detailed),
}).await?;
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### å·¥ä½œæµæ‰§è¡Œå¡ä½
```
åŸå› : èŠ‚ç‚¹ä¾èµ–æœªæ»¡è¶³æˆ–æ­»é”
è§£å†³:
1. æ£€æŸ¥å·¥ä½œæµå®šä¹‰çš„ä¾èµ–å…³ç³»
2. å¯ç”¨æ­»é”æ£€æµ‹: --enable-deadlock-detection true
3. å¢åŠ æ‰§è¡Œè¶…æ—¶: --execution-timeout 7200
```

#### AIæ¨ç†å¤±è´¥
```
åŸå› : æ¨¡å‹åŠ è½½å¤±è´¥æˆ–æ¨ç†è¶…æ—¶
è§£å†³:
1. æ£€æŸ¥AIæœåŠ¡è¿æ¥: --ai-service-url http://ai-service:8080
2. å¢åŠ æ¨ç†è¶…æ—¶: --ai-inference-timeout 600
3. å¯ç”¨é‡è¯•æœºåˆ¶: --ai-retry-enabled true
```

#### å†…å­˜ä¸è¶³
```
åŸå› : å¹¶å‘å·¥ä½œæµè¿‡å¤šæˆ–å†…å­˜æ³„æ¼
è§£å†³:
1. å‡å°‘å¹¶å‘æ•°: --max-concurrent-workflows 500
2. å¯ç”¨å†…å­˜ç›‘æ§: --enable-memory-monitoring true
3. å¢åŠ å®ä¾‹å†…å­˜: resources.limits.memory=4Gi
```

## ğŸ“š APIå‚è€ƒ

### REST API

```http
# åˆ›å»ºå·¥ä½œæµ
POST /api/v1/workflows
Content-Type: application/json

{
  "name": "my-workflow",
  "nodes": [...],
  "edges": [...]
}

# å¯åŠ¨å·¥ä½œæµå®ä¾‹
POST /api/v1/workflows/{workflow-id}/instances
Content-Type: application/json

{
  "context": {...}
}

# è·å–å®ä¾‹çŠ¶æ€
GET /api/v1/instances/{instance-id}

# è·å–æ‰§è¡Œç»“æœ
GET /api/v1/instances/{instance-id}/results
```

### WebSocket API

```javascript
// è¿æ¥åˆ°å·¥ä½œæµå¼•æ“
const ws = new WebSocket('ws://localhost:8080/ws/workflows');

// è®¢é˜…å·¥ä½œæµäº‹ä»¶
ws.send(JSON.stringify({
  type: 'subscribe',
  pattern: 'workflow.*'
}));

// æ¥æ”¶äº‹ä»¶
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Workflow event:', data);
};
```

## ğŸ¤ è´¡çŒ®

### å¼€å‘æŒ‡å—
1. Fork æœ¬ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature/new-workflow-node`
3. ç¼–å†™ä»£ç å’Œæµ‹è¯•
4. è¿è¡Œæµ‹è¯•: `cargo test`
5. æäº¤PR

### æ’ä»¶å¼€å‘
1. å®ç° `WorkflowNodePlugin` trait
2. æ·»åŠ æ’ä»¶é…ç½®æ–‡ä»¶
3. ç¼–å†™æ’ä»¶æ–‡æ¡£
4. æäº¤åˆ°æ’ä»¶ä»“åº“

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](../../LICENSE) æ–‡ä»¶